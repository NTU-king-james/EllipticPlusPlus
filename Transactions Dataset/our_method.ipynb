{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go \n",
    "import plotly.offline as py \n",
    "import math\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=19q09IFhfkOOBOXvn_dKhWjILJtjCcsjc\n",
      "From (redirected): https://drive.google.com/uc?id=19q09IFhfkOOBOXvn_dKhWjILJtjCcsjc&confirm=t&uuid=25cb662e-8826-43ae-b8a0-e2e3f228fefb\n",
      "To: /home/ck_bonbon/fintech/final_project/EllipticPlusPlus/Transactions Dataset/txs_features.csv\n",
      "100%|████████████████████████████████████████| 695M/695M [00:14<00:00, 47.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1DiBxn8TXdbJqoSw58pYUeaqO3oOKhuQO\n",
      "To: /home/ck_bonbon/fintech/final_project/EllipticPlusPlus/Transactions Dataset/txs_classes.csv\n",
      "100%|██████████████████████████████████████| 2.36M/2.36M [00:00<00:00, 57.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Q2yG_CIDvfdGP-fKVPSw979EYgQukjz5\n",
      "To: /home/ck_bonbon/fintech/final_project/EllipticPlusPlus/Transactions Dataset/txs_edgelist.csv\n",
      "100%|██████████████████████████████████████| 4.47M/4.47M [00:00<00:00, 17.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "!gdown --fuzzy \"https://drive.google.com/file/d/19q09IFhfkOOBOXvn_dKhWjILJtjCcsjc/view?usp=drive_link\"\n",
    "!gdown --fuzzy \"https://drive.google.com/file/d/1DiBxn8TXdbJqoSw58pYUeaqO3oOKhuQO/view?usp=drive_link\"\n",
    "!gdown --fuzzy \"https://drive.google.com/file/d/1Q2yG_CIDvfdGP-fKVPSw979EYgQukjz5/view?usp=drive_link\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transaction features: \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTransaction features: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m df_txs_features \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxs_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_txs_features\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTransaction classes: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\\nTransaction features: \\n\")\n",
    "df_txs_features = pd.read_csv(\"txs_features.csv\")\n",
    "df_txs_features\n",
    "\n",
    "print(\"\\nTransaction classes: \\n\")\n",
    "df_txs_classes = pd.read_csv(\"txs_classes.csv\")\n",
    "df_txs_classes\n",
    "\n",
    "print(\"\\nTransaction-Transaction edgelist: \\n\")\n",
    "df_txs_edgelist = pd.read_csv(\"txs_edgelist.csv\")\n",
    "df_txs_edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 把 feature DataFrame 裡含 NaN 的行丟掉\n",
    "df_txs_features = df_txs_features.dropna()\n",
    "# 2. 取出還在的 txId（假設 index 就是 txId）\n",
    "valid_tx = set(df_txs_features.index)\n",
    "\n",
    "# 3. 篩邊表：只保留 txId1 與 txId2 都在 valid_tx 裡面的邊\n",
    "df_txs_edgelist = df_txs_edgelist[\n",
    "    df_txs_edgelist['txId1'].isin(valid_tx) &\n",
    "    df_txs_edgelist['txId2'].isin(valid_tx)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>1.668990e-01</td>\n",
       "      <td>0.367074</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.266986</td>\n",
       "      <td>0.533972</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>...</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.611878</td>\n",
       "      <td>5.861940e-01</td>\n",
       "      <td>5.025584</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>2.805889</td>\n",
       "      <td>5.611778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51816</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>0.456608</td>\n",
       "      <td>2.279902e-01</td>\n",
       "      <td>0.228518</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.228254</td>\n",
       "      <td>0.456508</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68869</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.102967</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.308900</td>\n",
       "      <td>1.229000e+00</td>\n",
       "      <td>8.079800</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>4.654400</td>\n",
       "      <td>9.308800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89273</td>\n",
       "      <td>1</td>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>...</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>1.300000e-07</td>\n",
       "      <td>41.264036</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>852.164680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202799</th>\n",
       "      <td>194747812</td>\n",
       "      <td>49</td>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>...</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>115.952889</td>\n",
       "      <td>1.653300e+00</td>\n",
       "      <td>114.299544</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>57.976422</td>\n",
       "      <td>115.952844</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202800</th>\n",
       "      <td>194747925</td>\n",
       "      <td>49</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>...</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>114.250098</td>\n",
       "      <td>2.035300e-02</td>\n",
       "      <td>114.229700</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>57.125027</td>\n",
       "      <td>114.250053</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202801</th>\n",
       "      <td>194748063</td>\n",
       "      <td>49</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>113.606771</td>\n",
       "      <td>9.257490e-01</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>56.803363</td>\n",
       "      <td>113.606726</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202802</th>\n",
       "      <td>194748070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>...</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>112.680977</td>\n",
       "      <td>3.026970e-01</td>\n",
       "      <td>112.378235</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>56.340466</td>\n",
       "      <td>112.680932</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202803</th>\n",
       "      <td>194835939</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>0.399769</td>\n",
       "      <td>3.995460e-01</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>0.399546</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
       "0            3321          1        -0.169615        -0.184668   \n",
       "1           11108          1        -0.137586        -0.184668   \n",
       "2           51816          1        -0.170103        -0.184668   \n",
       "3           68869          1        -0.114267        -0.184668   \n",
       "4           89273          1         5.202107        -0.210553   \n",
       "...           ...        ...              ...              ...   \n",
       "202799  194747812         49         0.558398        -0.198956   \n",
       "202800  194747925         49         0.547658        -0.198956   \n",
       "202801  194748063         49         0.543600        -0.198853   \n",
       "202802  194748070         49         0.537760        -0.198853   \n",
       "202803  194835939         49        -0.170463        -0.152788   \n",
       "\n",
       "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
       "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
       "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
       "...                 ...              ...              ...              ...   \n",
       "202799        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202800        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202801        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202802        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202803         1.018602        -0.121970        -0.063725        -0.113002   \n",
       "\n",
       "        Local_feature_7  Local_feature_8  ...  in_BTC_max  in_BTC_mean  \\\n",
       "0             -0.061584        -0.160199  ...    0.534072     0.534072   \n",
       "1             -0.061584        -0.127429  ...    5.611878     5.611878   \n",
       "2             -0.061584        -0.160699  ...    0.456608     0.456608   \n",
       "3              0.547008        -0.161652  ...    8.000000     3.102967   \n",
       "4             -0.061584         5.335864  ...  852.164680   852.164680   \n",
       "...                 ...              ...  ...         ...          ...   \n",
       "202799        -0.061584         0.584665  ...  115.952889   115.952889   \n",
       "202800        -0.061584         0.573676  ...  114.250098   114.250098   \n",
       "202801        -0.061584         0.569524  ...  113.606771   113.606771   \n",
       "202802        -0.061584         0.563549  ...  112.680977   112.680977   \n",
       "202803        -0.061584        -0.161066  ...    0.399769     0.399769   \n",
       "\n",
       "        in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  out_BTC_mean  \\\n",
       "0            0.534072      0.534072  1.668990e-01     0.367074      0.266986   \n",
       "1            5.611878      5.611878  5.861940e-01     5.025584      2.805889   \n",
       "2            0.456608      0.456608  2.279902e-01     0.228518      0.228254   \n",
       "3            1.000000      9.308900  1.229000e+00     8.079800      4.654400   \n",
       "4          852.164680    852.164680  1.300000e-07    41.264036      0.065016   \n",
       "...               ...           ...           ...          ...           ...   \n",
       "202799     115.952889    115.952889  1.653300e+00   114.299544     57.976422   \n",
       "202800     114.250098    114.250098  2.035300e-02   114.229700     57.125027   \n",
       "202801     113.606771    113.606771  9.257490e-01   112.680977     56.803363   \n",
       "202802     112.680977    112.680977  3.026970e-01   112.378235     56.340466   \n",
       "202803       0.399769      0.399769  3.995460e-01     0.399546      0.399546   \n",
       "\n",
       "        out_BTC_median  out_BTC_total  class  \n",
       "0             0.266986       0.533972      3  \n",
       "1             2.805889       5.611778      3  \n",
       "2             0.228254       0.456508      3  \n",
       "3             4.654400       9.308800      2  \n",
       "4             0.000441     852.164680      2  \n",
       "...                ...            ...    ...  \n",
       "202799       57.976422     115.952844      3  \n",
       "202800       57.125027     114.250053      3  \n",
       "202801       56.803363     113.606726      3  \n",
       "202802       56.340466     112.680932      3  \n",
       "202803        0.399546       0.399546      3  \n",
       "\n",
       "[202804 rows x 185 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "subset = df_txs_classes[['txId', 'class']]\n",
    "\n",
    "# 2. 用 merge 把 class 欄併到 txs_features\n",
    "df_txs_features = df_txs_features.merge(\n",
    "    subset,\n",
    "    on='txId',     # 以 txId 當作 key\n",
    "    how='left'     # 保留 txs_features 所有列，對不到的 class 欄會是 NaN\n",
    ")\n",
    "#df_txs_features = df_txs_features.dropna()\n",
    "df_txs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-35 {color: black;}#sk-container-id-35 pre{padding: 0;}#sk-container-id-35 div.sk-toggleable {background-color: white;}#sk-container-id-35 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-35 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-35 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-35 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-35 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-35 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-35 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-35 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-35 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-35 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-35 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-35 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-35 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-35 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-35 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-35 div.sk-item {position: relative;z-index: 1;}#sk-container-id-35 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-35 div.sk-item::before, #sk-container-id-35 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-35 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-35 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-35 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-35 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-35 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-35 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-35 div.sk-label-container {text-align: center;}#sk-container-id-35 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-35 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-35\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" checked><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-36 {color: black;}#sk-container-id-36 pre{padding: 0;}#sk-container-id-36 div.sk-toggleable {background-color: white;}#sk-container-id-36 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-36 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-36 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-36 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-36 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-36 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-36 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-36 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-36 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-36 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-36 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-36 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-36 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-36 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-36 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-36 div.sk-item {position: relative;z-index: 1;}#sk-container-id-36 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-36 div.sk-item::before, #sk-container-id-36 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-36 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-36 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-36 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-36 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-36 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-36 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-36 div.sk-label-container {text-align: center;}#sk-container-id-36 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-36 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-36\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" checked><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-37 {color: black;}#sk-container-id-37 pre{padding: 0;}#sk-container-id-37 div.sk-toggleable {background-color: white;}#sk-container-id-37 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-37 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-37 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-37 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-37 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-37 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-37 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-37 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-37 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-37 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-37 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-37 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-37 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-37 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-37 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-37 div.sk-item {position: relative;z-index: 1;}#sk-container-id-37 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-37 div.sk-item::before, #sk-container-id-37 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-37 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-37 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-37 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-37 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-37 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-37 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-37 div.sk-label-container {text-align: center;}#sk-container-id-37 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-37 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-37\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" checked><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-38 {color: black;}#sk-container-id-38 pre{padding: 0;}#sk-container-id-38 div.sk-toggleable {background-color: white;}#sk-container-id-38 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-38 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-38 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-38 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-38 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-38 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-38 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-38 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-38 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-38 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-38 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-38 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-38 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-38 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-38 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-38 div.sk-item {position: relative;z-index: 1;}#sk-container-id-38 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-38 div.sk-item::before, #sk-container-id-38 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-38 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-38 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-38 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-38 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-38 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-38 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-38 div.sk-label-container {text-align: center;}#sk-container-id-38 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-38 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-38\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" checked><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-39 {color: black;}#sk-container-id-39 pre{padding: 0;}#sk-container-id-39 div.sk-toggleable {background-color: white;}#sk-container-id-39 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-39 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-39 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-39 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-39 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-39 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-39 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-39 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-39 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-39 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-39 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-39 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-39 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-39 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-39 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-39 div.sk-item {position: relative;z-index: 1;}#sk-container-id-39 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-39 div.sk-item::before, #sk-container-id-39 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-39 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-39 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-39 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-39 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-39 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-39 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-39 div.sk-label-container {text-align: center;}#sk-container-id-39 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-39 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-39\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" checked><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-40 {color: black;}#sk-container-id-40 pre{padding: 0;}#sk-container-id-40 div.sk-toggleable {background-color: white;}#sk-container-id-40 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-40 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-40 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-40 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-40 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-40 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-40 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-40 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-40 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-40 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-40 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-40 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-40 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-40 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-40 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-40 div.sk-item {position: relative;z-index: 1;}#sk-container-id-40 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-40 div.sk-item::before, #sk-container-id-40 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-40 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-40 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-40 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-40 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-40 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-40 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-40 div.sk-label-container {text-align: center;}#sk-container-id-40 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-40 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-40\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" checked><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-41 {color: black;}#sk-container-id-41 pre{padding: 0;}#sk-container-id-41 div.sk-toggleable {background-color: white;}#sk-container-id-41 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-41 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-41 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-41 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-41 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-41 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-41 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-41 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-41 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-41 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-41 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-41 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-41 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-41 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-41 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-41 div.sk-item {position: relative;z-index: 1;}#sk-container-id-41 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-41 div.sk-item::before, #sk-container-id-41 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-41 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-41 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-41 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-41 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-41 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-41 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-41 div.sk-label-container {text-align: center;}#sk-container-id-41 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-41 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-41\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" checked><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-42 {color: black;}#sk-container-id-42 pre{padding: 0;}#sk-container-id-42 div.sk-toggleable {background-color: white;}#sk-container-id-42 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-42 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-42 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-42 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-42 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-42 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-42 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-42 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-42 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-42 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-42 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-42 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-42 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-42 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-42 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-42 div.sk-item {position: relative;z-index: 1;}#sk-container-id-42 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-42 div.sk-item::before, #sk-container-id-42 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-42 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-42 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-42 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-42 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-42 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-42 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-42 div.sk-label-container {text-align: center;}#sk-container-id-42 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-42 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-42\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-43 {color: black;}#sk-container-id-43 pre{padding: 0;}#sk-container-id-43 div.sk-toggleable {background-color: white;}#sk-container-id-43 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-43 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-43 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-43 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-43 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-43 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-43 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-43 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-43 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-43 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-43 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-43 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-43 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-43 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-43 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-43 div.sk-item {position: relative;z-index: 1;}#sk-container-id-43 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-43 div.sk-item::before, #sk-container-id-43 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-43 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-43 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-43 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-43 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-43 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-43 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-43 div.sk-label-container {text-align: center;}#sk-container-id-43 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-43 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-43\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" checked><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-44 {color: black;}#sk-container-id-44 pre{padding: 0;}#sk-container-id-44 div.sk-toggleable {background-color: white;}#sk-container-id-44 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-44 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-44 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-44 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-44 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-44 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-44 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-44 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-44 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-44 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-44 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-44 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-44 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-44 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-44 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-44 div.sk-item {position: relative;z-index: 1;}#sk-container-id-44 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-44 div.sk-item::before, #sk-container-id-44 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-44 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-44 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-44 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-44 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-44 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-44 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-44 div.sk-label-container {text-align: center;}#sk-container-id-44 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-44 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-44\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" checked><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-45 {color: black;}#sk-container-id-45 pre{padding: 0;}#sk-container-id-45 div.sk-toggleable {background-color: white;}#sk-container-id-45 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-45 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-45 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-45 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-45 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-45 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-45 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-45 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-45 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-45 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-45 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-45 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-45 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-45 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-45 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-45 div.sk-item {position: relative;z-index: 1;}#sk-container-id-45 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-45 div.sk-item::before, #sk-container-id-45 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-45 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-45 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-45 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-45 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-45 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-45 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-45 div.sk-label-container {text-align: center;}#sk-container-id-45 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-45 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-45\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" checked><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-46 {color: black;}#sk-container-id-46 pre{padding: 0;}#sk-container-id-46 div.sk-toggleable {background-color: white;}#sk-container-id-46 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-46 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-46 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-46 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-46 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-46 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-46 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-46 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-46 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-46 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-46 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-46 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-46 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-46 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-46 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-46 div.sk-item {position: relative;z-index: 1;}#sk-container-id-46 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-46 div.sk-item::before, #sk-container-id-46 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-46 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-46 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-46 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-46 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-46 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-46 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-46 div.sk-label-container {text-align: center;}#sk-container-id-46 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-46 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-46\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" checked><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-47 {color: black;}#sk-container-id-47 pre{padding: 0;}#sk-container-id-47 div.sk-toggleable {background-color: white;}#sk-container-id-47 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-47 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-47 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-47 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-47 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-47 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-47 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-47 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-47 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-47 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-47 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-47 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-47 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-47 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-47 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-47 div.sk-item {position: relative;z-index: 1;}#sk-container-id-47 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-47 div.sk-item::before, #sk-container-id-47 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-47 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-47 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-47 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-47 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-47 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-47 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-47 div.sk-label-container {text-align: center;}#sk-container-id-47 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-47 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-47\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" checked><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-48 {color: black;}#sk-container-id-48 pre{padding: 0;}#sk-container-id-48 div.sk-toggleable {background-color: white;}#sk-container-id-48 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-48 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-48 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-48 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-48 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-48 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-48 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-48 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-48 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-48 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-48 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-48 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-48 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-48 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-48 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-48 div.sk-item {position: relative;z-index: 1;}#sk-container-id-48 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-48 div.sk-item::before, #sk-container-id-48 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-48 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-48 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-48 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-48 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-48 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-48 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-48 div.sk-label-container {text-align: center;}#sk-container-id-48 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-48 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-48\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" checked><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-49 {color: black;}#sk-container-id-49 pre{padding: 0;}#sk-container-id-49 div.sk-toggleable {background-color: white;}#sk-container-id-49 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-49 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-49 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-49 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-49 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-49 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-49 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-49 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-49 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-49 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-49 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-49 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-49 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-49 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-49 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-49 div.sk-item {position: relative;z-index: 1;}#sk-container-id-49 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-49 div.sk-item::before, #sk-container-id-49 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-49 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-49 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-49 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-49 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-49 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-49 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-49 div.sk-label-container {text-align: center;}#sk-container-id-49 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-49 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-49\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" checked><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-50 {color: black;}#sk-container-id-50 pre{padding: 0;}#sk-container-id-50 div.sk-toggleable {background-color: white;}#sk-container-id-50 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-50 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-50 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-50 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-50 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-50 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-50 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-50 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-50 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-50 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-50 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-50 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-50 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-50 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-50 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-50 div.sk-item {position: relative;z-index: 1;}#sk-container-id-50 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-50 div.sk-item::before, #sk-container-id-50 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-50 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-50 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-50 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-50 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-50 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-50 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-50 div.sk-label-container {text-align: center;}#sk-container-id-50 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-50 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-50\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" checked><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-51 {color: black;}#sk-container-id-51 pre{padding: 0;}#sk-container-id-51 div.sk-toggleable {background-color: white;}#sk-container-id-51 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-51 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-51 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-51 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-51 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-51 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-51 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-51 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-51 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-51 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-51 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-51 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-51 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-51 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-51 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-51 div.sk-item {position: relative;z-index: 1;}#sk-container-id-51 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-51 div.sk-item::before, #sk-container-id-51 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-51 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-51 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-51 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-51 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-51 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-51 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-51 div.sk-label-container {text-align: center;}#sk-container-id-51 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-51 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-51\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" checked><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For notmalize augmented features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for column in df_txs_features.columns[-18:-1]:\n",
    "    feature = np.array(df_txs_features[column]).reshape(-1,1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(feature)\n",
    "    feature_scaled = scaler.transform(feature)\n",
    "    df_txs_features[column] = feature_scaled.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txId</th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3321</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>8.301504e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8.904096e-05</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11108</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>2.915711e-04</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>9.357923e-04</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51816</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.134016e-04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7.612341e-05</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68869</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>6.113009e-04</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>1.552291e-03</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89273</td>\n",
       "      <td>1</td>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>6.466160e-11</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.451405e-07</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202799</th>\n",
       "      <td>194747812</td>\n",
       "      <td>49</td>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>8.223464e-04</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>1.933576e-02</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202800</th>\n",
       "      <td>194747925</td>\n",
       "      <td>49</td>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>1.012352e-05</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>1.905181e-02</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202801</th>\n",
       "      <td>194748063</td>\n",
       "      <td>49</td>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>4.604647e-04</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>1.894453e-02</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202802</th>\n",
       "      <td>194748070</td>\n",
       "      <td>49</td>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>1.505606e-04</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>1.879015e-02</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202803</th>\n",
       "      <td>194835939</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.987330e-04</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.332511e-04</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             txId  Time step  Local_feature_1  Local_feature_2  \\\n",
       "0            3321          1        -0.169615        -0.184668   \n",
       "1           11108          1        -0.137586        -0.184668   \n",
       "2           51816          1        -0.170103        -0.184668   \n",
       "3           68869          1        -0.114267        -0.184668   \n",
       "4           89273          1         5.202107        -0.210553   \n",
       "...           ...        ...              ...              ...   \n",
       "202799  194747812         49         0.558398        -0.198956   \n",
       "202800  194747925         49         0.547658        -0.198956   \n",
       "202801  194748063         49         0.543600        -0.198853   \n",
       "202802  194748070         49         0.537760        -0.198853   \n",
       "202803  194835939         49        -0.170463        -0.152788   \n",
       "\n",
       "        Local_feature_3  Local_feature_4  Local_feature_5  Local_feature_6  \\\n",
       "0             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "1             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "2             -1.201369        -0.121970        -0.043875        -0.113002   \n",
       "3             -1.201369         0.028105        -0.043875        -0.113002   \n",
       "4             -1.756361        -0.121970       260.090707        -0.113002   \n",
       "...                 ...              ...              ...              ...   \n",
       "202799        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202800        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202801        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202802        -0.091383        -0.121970        -0.043875        -0.113002   \n",
       "202803         1.018602        -0.121970        -0.063725        -0.113002   \n",
       "\n",
       "        Local_feature_7  Local_feature_8  ...  in_BTC_max  in_BTC_mean  \\\n",
       "0             -0.061584        -0.160199  ...    0.000047     0.000047   \n",
       "1             -0.061584        -0.127429  ...    0.000493     0.000493   \n",
       "2             -0.061584        -0.160699  ...    0.000040     0.000040   \n",
       "3              0.547008        -0.161652  ...    0.000702     0.000272   \n",
       "4             -0.061584         5.335864  ...    0.074805     0.074805   \n",
       "...                 ...              ...  ...         ...          ...   \n",
       "202799        -0.061584         0.584665  ...    0.010179     0.010179   \n",
       "202800        -0.061584         0.573676  ...    0.010029     0.010029   \n",
       "202801        -0.061584         0.569524  ...    0.009973     0.009973   \n",
       "202802        -0.061584         0.563549  ...    0.009891     0.009891   \n",
       "202803        -0.061584        -0.161066  ...    0.000035     0.000035   \n",
       "\n",
       "        in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  out_BTC_mean  \\\n",
       "0            0.000047      0.000047  8.301504e-05     0.000032      0.000089   \n",
       "1            0.000493      0.000493  2.915711e-04     0.000444      0.000936   \n",
       "2            0.000040      0.000040  1.134016e-04     0.000020      0.000076   \n",
       "3            0.000088      0.000817  6.113009e-04     0.000714      0.001552   \n",
       "4            0.074805      0.074805  6.466160e-11     0.003648      0.000022   \n",
       "...               ...           ...           ...          ...           ...   \n",
       "202799       0.010179      0.010179  8.223464e-04     0.010104      0.019336   \n",
       "202800       0.010029      0.010029  1.012352e-05     0.010098      0.019052   \n",
       "202801       0.009973      0.009973  4.604647e-04     0.009961      0.018945   \n",
       "202802       0.009891      0.009891  1.505606e-04     0.009935      0.018790   \n",
       "202803       0.000035      0.000035  1.987330e-04     0.000035      0.000133   \n",
       "\n",
       "        out_BTC_median  out_BTC_total  class  \n",
       "0         8.904096e-05       0.000047      3  \n",
       "1         9.357923e-04       0.000493      3  \n",
       "2         7.612341e-05       0.000040      3  \n",
       "3         1.552291e-03       0.000817      2  \n",
       "4         1.451405e-07       0.074805      2  \n",
       "...                ...            ...    ...  \n",
       "202799    1.933576e-02       0.010179      3  \n",
       "202800    1.905181e-02       0.010029      3  \n",
       "202801    1.894453e-02       0.009973      3  \n",
       "202802    1.879015e-02       0.009891      3  \n",
       "202803    1.332511e-04       0.000035      3  \n",
       "\n",
       "[202804 rows x 185 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time step</th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>Local_feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.168500</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.046932</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.029140</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163591</td>\n",
       "      <td>-0.164980</td>\n",
       "      <td>...</td>\n",
       "      <td>6.180084e-05</td>\n",
       "      <td>3.127478e-05</td>\n",
       "      <td>3.127597e-05</td>\n",
       "      <td>6.254833e-05</td>\n",
       "      <td>6.676470e-06</td>\n",
       "      <td>6.164291e-05</td>\n",
       "      <td>1.185148e-04</td>\n",
       "      <td>1.185150e-04</td>\n",
       "      <td>6.238815e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>6</td>\n",
       "      <td>-0.170834</td>\n",
       "      <td>-0.131425</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.055376</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163572</td>\n",
       "      <td>-0.167757</td>\n",
       "      <td>...</td>\n",
       "      <td>2.350094e-05</td>\n",
       "      <td>9.975293e-06</td>\n",
       "      <td>5.421152e-06</td>\n",
       "      <td>2.992583e-05</td>\n",
       "      <td>9.815134e-08</td>\n",
       "      <td>2.194331e-05</td>\n",
       "      <td>1.622788e-05</td>\n",
       "      <td>8.509850e-06</td>\n",
       "      <td>2.990209e-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>34</td>\n",
       "      <td>1.305212</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>97.300650</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>1.348765</td>\n",
       "      <td>1.321754</td>\n",
       "      <td>...</td>\n",
       "      <td>2.057192e-02</td>\n",
       "      <td>2.057192e-02</td>\n",
       "      <td>2.057192e-02</td>\n",
       "      <td>2.057192e-02</td>\n",
       "      <td>5.070912e-07</td>\n",
       "      <td>2.430414e-04</td>\n",
       "      <td>1.592931e-05</td>\n",
       "      <td>5.025955e-06</td>\n",
       "      <td>2.057192e-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>-0.166062</td>\n",
       "      <td>...</td>\n",
       "      <td>4.688075e-05</td>\n",
       "      <td>4.688076e-05</td>\n",
       "      <td>4.688195e-05</td>\n",
       "      <td>4.687833e-05</td>\n",
       "      <td>8.301504e-05</td>\n",
       "      <td>3.244988e-05</td>\n",
       "      <td>8.904078e-05</td>\n",
       "      <td>8.904096e-05</td>\n",
       "      <td>4.687265e-05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>48</td>\n",
       "      <td>-0.086232</td>\n",
       "      <td>-0.101835</td>\n",
       "      <td>-0.646376</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>17.046997</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.074885</td>\n",
       "      <td>-0.081943</td>\n",
       "      <td>...</td>\n",
       "      <td>1.207336e-03</td>\n",
       "      <td>1.207336e-03</td>\n",
       "      <td>1.207337e-03</td>\n",
       "      <td>1.207333e-03</td>\n",
       "      <td>5.184866e-08</td>\n",
       "      <td>2.625465e-04</td>\n",
       "      <td>5.313067e-06</td>\n",
       "      <td>7.031674e-07</td>\n",
       "      <td>1.207300e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403203785</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.172978</td>\n",
       "      <td>-0.172527</td>\n",
       "      <td>0.463609</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163640</td>\n",
       "      <td>-0.169455</td>\n",
       "      <td>...</td>\n",
       "      <td>7.368421e-08</td>\n",
       "      <td>7.369663e-08</td>\n",
       "      <td>7.488595e-08</td>\n",
       "      <td>7.126406e-08</td>\n",
       "      <td>5.282356e-08</td>\n",
       "      <td>5.251141e-08</td>\n",
       "      <td>1.157616e-07</td>\n",
       "      <td>1.159417e-07</td>\n",
       "      <td>6.146496e-08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403234712</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.172669</td>\n",
       "      <td>-0.158783</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163323</td>\n",
       "      <td>-0.169142</td>\n",
       "      <td>...</td>\n",
       "      <td>4.387898e-06</td>\n",
       "      <td>4.387910e-06</td>\n",
       "      <td>4.389099e-06</td>\n",
       "      <td>4.385477e-06</td>\n",
       "      <td>2.477037e-05</td>\n",
       "      <td>4.401941e-06</td>\n",
       "      <td>1.660683e-05</td>\n",
       "      <td>1.660701e-05</td>\n",
       "      <td>4.371017e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403234715</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.172669</td>\n",
       "      <td>-0.158783</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163323</td>\n",
       "      <td>-0.169142</td>\n",
       "      <td>...</td>\n",
       "      <td>4.387898e-06</td>\n",
       "      <td>4.387910e-06</td>\n",
       "      <td>4.389099e-06</td>\n",
       "      <td>4.385477e-06</td>\n",
       "      <td>2.477037e-05</td>\n",
       "      <td>4.401941e-06</td>\n",
       "      <td>1.660683e-05</td>\n",
       "      <td>1.660701e-05</td>\n",
       "      <td>4.371017e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403235564</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.172669</td>\n",
       "      <td>-0.158783</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.163323</td>\n",
       "      <td>-0.169142</td>\n",
       "      <td>...</td>\n",
       "      <td>4.387898e-06</td>\n",
       "      <td>4.387910e-06</td>\n",
       "      <td>4.389099e-06</td>\n",
       "      <td>4.385477e-06</td>\n",
       "      <td>2.477037e-05</td>\n",
       "      <td>4.401941e-06</td>\n",
       "      <td>1.660683e-05</td>\n",
       "      <td>1.660701e-05</td>\n",
       "      <td>4.371017e-06</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403244581</th>\n",
       "      <td>28</td>\n",
       "      <td>-0.143292</td>\n",
       "      <td>-0.158783</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.133266</td>\n",
       "      <td>-0.139507</td>\n",
       "      <td>...</td>\n",
       "      <td>4.132228e-04</td>\n",
       "      <td>4.132228e-04</td>\n",
       "      <td>4.132240e-04</td>\n",
       "      <td>4.132204e-04</td>\n",
       "      <td>5.242564e-05</td>\n",
       "      <td>4.068115e-04</td>\n",
       "      <td>7.849469e-04</td>\n",
       "      <td>7.849471e-04</td>\n",
       "      <td>4.132059e-04</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 184 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time step  Local_feature_1  Local_feature_2  Local_feature_3  \\\n",
       "txId                                                                      \n",
       "1076              48        -0.168500         0.270909        -0.091383   \n",
       "2534               6        -0.170834        -0.131425         1.018602   \n",
       "3181              34         1.305212        -0.210553        -1.756361   \n",
       "3321               1        -0.169615        -0.184668        -1.201369   \n",
       "3889              48        -0.086232        -0.101835        -0.646376   \n",
       "...              ...              ...              ...              ...   \n",
       "403203785         28        -0.172978        -0.172527         0.463609   \n",
       "403234712         28        -0.172669        -0.158783        -1.201369   \n",
       "403234715         28        -0.172669        -0.158783        -1.201369   \n",
       "403235564         28        -0.172669        -0.158783        -1.201369   \n",
       "403244581         28        -0.143292        -0.158783        -1.201369   \n",
       "\n",
       "           Local_feature_4  Local_feature_5  Local_feature_6  Local_feature_7  \\\n",
       "txId                                                                            \n",
       "1076             -0.046932        -0.043875        -0.029140        -0.061584   \n",
       "2534              0.028105         0.055376         0.054722        -0.061584   \n",
       "3181             -0.121970        97.300650        -0.113002        -0.061584   \n",
       "3321             -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "3889             -0.121970        17.046997        -0.113002        -0.061584   \n",
       "...                    ...              ...              ...              ...   \n",
       "403203785        -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "403234712        -0.121970        -0.063725        -0.113002        -0.061584   \n",
       "403234715        -0.121970        -0.063725        -0.113002        -0.061584   \n",
       "403235564        -0.121970        -0.063725        -0.113002        -0.061584   \n",
       "403244581        -0.121970        -0.043875        -0.113002        -0.061584   \n",
       "\n",
       "           Local_feature_8  Local_feature_9  ...    in_BTC_max   in_BTC_mean  \\\n",
       "txId                                         ...                               \n",
       "1076             -0.163591        -0.164980  ...  6.180084e-05  3.127478e-05   \n",
       "2534             -0.163572        -0.167757  ...  2.350094e-05  9.975293e-06   \n",
       "3181              1.348765         1.321754  ...  2.057192e-02  2.057192e-02   \n",
       "3321             -0.160199        -0.166062  ...  4.688075e-05  4.688076e-05   \n",
       "3889             -0.074885        -0.081943  ...  1.207336e-03  1.207336e-03   \n",
       "...                    ...              ...  ...           ...           ...   \n",
       "403203785        -0.163640        -0.169455  ...  7.368421e-08  7.369663e-08   \n",
       "403234712        -0.163323        -0.169142  ...  4.387898e-06  4.387910e-06   \n",
       "403234715        -0.163323        -0.169142  ...  4.387898e-06  4.387910e-06   \n",
       "403235564        -0.163323        -0.169142  ...  4.387898e-06  4.387910e-06   \n",
       "403244581        -0.133266        -0.139507  ...  4.132228e-04  4.132228e-04   \n",
       "\n",
       "           in_BTC_median  in_BTC_total   out_BTC_min   out_BTC_max  \\\n",
       "txId                                                                 \n",
       "1076        3.127597e-05  6.254833e-05  6.676470e-06  6.164291e-05   \n",
       "2534        5.421152e-06  2.992583e-05  9.815134e-08  2.194331e-05   \n",
       "3181        2.057192e-02  2.057192e-02  5.070912e-07  2.430414e-04   \n",
       "3321        4.688195e-05  4.687833e-05  8.301504e-05  3.244988e-05   \n",
       "3889        1.207337e-03  1.207333e-03  5.184866e-08  2.625465e-04   \n",
       "...                  ...           ...           ...           ...   \n",
       "403203785   7.488595e-08  7.126406e-08  5.282356e-08  5.251141e-08   \n",
       "403234712   4.389099e-06  4.385477e-06  2.477037e-05  4.401941e-06   \n",
       "403234715   4.389099e-06  4.385477e-06  2.477037e-05  4.401941e-06   \n",
       "403235564   4.389099e-06  4.385477e-06  2.477037e-05  4.401941e-06   \n",
       "403244581   4.132240e-04  4.132204e-04  5.242564e-05  4.068115e-04   \n",
       "\n",
       "           out_BTC_mean  out_BTC_median  out_BTC_total  class  \n",
       "txId                                                           \n",
       "1076       1.185148e-04    1.185150e-04   6.238815e-05      3  \n",
       "2534       1.622788e-05    8.509850e-06   2.990209e-05      2  \n",
       "3181       1.592931e-05    5.025955e-06   2.057192e-02      2  \n",
       "3321       8.904078e-05    8.904096e-05   4.687265e-05      3  \n",
       "3889       5.313067e-06    7.031674e-07   1.207300e-03      3  \n",
       "...                 ...             ...            ...    ...  \n",
       "403203785  1.157616e-07    1.159417e-07   6.146496e-08      3  \n",
       "403234712  1.660683e-05    1.660701e-05   4.371017e-06      3  \n",
       "403234715  1.660683e-05    1.660701e-05   4.371017e-06      3  \n",
       "403235564  1.660683e-05    1.660701e-05   4.371017e-06      3  \n",
       "403244581  7.849469e-04    7.849471e-04   4.132059e-04      3  \n",
       "\n",
       "[202804 rows x 184 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txs_features = df_txs_features.set_index('txId')\n",
    "df_txs_features.sort_index()\n",
    "y = df_txs_features['class']\n",
    "time_steps = df_txs_features['Time step']\n",
    "train_mask = time_steps <= 34\n",
    "test_mask = time_steps > 34\n",
    "df_txs_features = df_txs_features.drop(columns=['class', 'Time step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>Local_feature_9</th>\n",
       "      <th>Local_feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_min</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>-0.166062</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>8.301504e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8.904096e-05</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11108</th>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>-0.133751</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>2.915711e-04</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>9.357923e-04</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51816</th>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>-0.166555</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.134016e-04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7.612341e-05</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68869</th>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>-0.118555</td>\n",
       "      <td>0.300047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>6.113009e-04</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>1.552291e-03</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89273</th>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>5.252974</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>6.466160e-11</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.451405e-07</td>\n",
       "      <td>0.074805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194747812</th>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>8.223464e-04</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>1.933576e-02</td>\n",
       "      <td>0.010179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194747925</th>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>0.557528</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>1.012352e-05</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>1.905181e-02</td>\n",
       "      <td>0.010029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194748063</th>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>0.553434</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>4.604647e-04</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>1.894453e-02</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194748070</th>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>0.547543</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>1.505606e-04</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>1.879015e-02</td>\n",
       "      <td>0.009891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194835939</th>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>-0.166917</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.987330e-04</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.332511e-04</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Local_feature_1  Local_feature_2  Local_feature_3  Local_feature_4  \\\n",
       "txId                                                                            \n",
       "3321             -0.169615        -0.184668        -1.201369        -0.121970   \n",
       "11108            -0.137586        -0.184668        -1.201369        -0.121970   \n",
       "51816            -0.170103        -0.184668        -1.201369        -0.121970   \n",
       "68869            -0.114267        -0.184668        -1.201369         0.028105   \n",
       "89273             5.202107        -0.210553        -1.756361        -0.121970   \n",
       "...                    ...              ...              ...              ...   \n",
       "194747812         0.558398        -0.198956        -0.091383        -0.121970   \n",
       "194747925         0.547658        -0.198956        -0.091383        -0.121970   \n",
       "194748063         0.543600        -0.198853        -0.091383        -0.121970   \n",
       "194748070         0.537760        -0.198853        -0.091383        -0.121970   \n",
       "194835939        -0.170463        -0.152788         1.018602        -0.121970   \n",
       "\n",
       "           Local_feature_5  Local_feature_6  Local_feature_7  Local_feature_8  \\\n",
       "txId                                                                            \n",
       "3321             -0.043875        -0.113002        -0.061584        -0.160199   \n",
       "11108            -0.043875        -0.113002        -0.061584        -0.127429   \n",
       "51816            -0.043875        -0.113002        -0.061584        -0.160699   \n",
       "68869            -0.043875        -0.113002         0.547008        -0.161652   \n",
       "89273           260.090707        -0.113002        -0.061584         5.335864   \n",
       "...                    ...              ...              ...              ...   \n",
       "194747812        -0.043875        -0.113002        -0.061584         0.584665   \n",
       "194747925        -0.043875        -0.113002        -0.061584         0.573676   \n",
       "194748063        -0.043875        -0.113002        -0.061584         0.569524   \n",
       "194748070        -0.043875        -0.113002        -0.061584         0.563549   \n",
       "194835939        -0.063725        -0.113002        -0.061584        -0.161066   \n",
       "\n",
       "           Local_feature_9  Local_feature_10  ...  in_BTC_min  in_BTC_max  \\\n",
       "txId                                          ...                           \n",
       "3321             -0.166062         -0.049707  ...    0.000047    0.000047   \n",
       "11108            -0.133751         -0.049707  ...    0.000493    0.000493   \n",
       "51816            -0.166555         -0.049707  ...    0.000040    0.000040   \n",
       "68869            -0.118555          0.300047  ...    0.000027    0.000702   \n",
       "89273             5.252974         -0.049707  ...    0.074805    0.074805   \n",
       "...                    ...               ...  ...         ...         ...   \n",
       "194747812         0.568363         -0.049707  ...    0.010179    0.010179   \n",
       "194747925         0.557528         -0.049707  ...    0.010029    0.010029   \n",
       "194748063         0.553434         -0.049707  ...    0.009973    0.009973   \n",
       "194748070         0.547543         -0.049707  ...    0.009891    0.009891   \n",
       "194835939        -0.166917         -0.049707  ...    0.000035    0.000035   \n",
       "\n",
       "           in_BTC_mean  in_BTC_median  in_BTC_total   out_BTC_min  \\\n",
       "txId                                                                \n",
       "3321          0.000047       0.000047      0.000047  8.301504e-05   \n",
       "11108         0.000493       0.000493      0.000493  2.915711e-04   \n",
       "51816         0.000040       0.000040      0.000040  1.134016e-04   \n",
       "68869         0.000272       0.000088      0.000817  6.113009e-04   \n",
       "89273         0.074805       0.074805      0.074805  6.466160e-11   \n",
       "...                ...            ...           ...           ...   \n",
       "194747812     0.010179       0.010179      0.010179  8.223464e-04   \n",
       "194747925     0.010029       0.010029      0.010029  1.012352e-05   \n",
       "194748063     0.009973       0.009973      0.009973  4.604647e-04   \n",
       "194748070     0.009891       0.009891      0.009891  1.505606e-04   \n",
       "194835939     0.000035       0.000035      0.000035  1.987330e-04   \n",
       "\n",
       "           out_BTC_max  out_BTC_mean  out_BTC_median  out_BTC_total  \n",
       "txId                                                                 \n",
       "3321          0.000032      0.000089    8.904096e-05       0.000047  \n",
       "11108         0.000444      0.000936    9.357923e-04       0.000493  \n",
       "51816         0.000020      0.000076    7.612341e-05       0.000040  \n",
       "68869         0.000714      0.001552    1.552291e-03       0.000817  \n",
       "89273         0.003648      0.000022    1.451405e-07       0.074805  \n",
       "...                ...           ...             ...            ...  \n",
       "194747812     0.010104      0.019336    1.933576e-02       0.010179  \n",
       "194747925     0.010098      0.019052    1.905181e-02       0.010029  \n",
       "194748063     0.009961      0.018945    1.894453e-02       0.009973  \n",
       "194748070     0.009935      0.018790    1.879015e-02       0.009891  \n",
       "194835939     0.000035      0.000133    1.332511e-04       0.000035  \n",
       "\n",
       "[202804 rows x 182 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txs_features\n",
    "y[y == 2] = 0\n",
    "y[y == 3] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "txId\n",
       "3321         2\n",
       "11108        2\n",
       "51816        2\n",
       "68869        0\n",
       "89273        0\n",
       "            ..\n",
       "194747812    2\n",
       "194747925    2\n",
       "194748063    2\n",
       "194748070    2\n",
       "194835939    2\n",
       "Name: class, Length: 202804, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Local_feature_1</th>\n",
       "      <th>Local_feature_2</th>\n",
       "      <th>Local_feature_3</th>\n",
       "      <th>Local_feature_4</th>\n",
       "      <th>Local_feature_5</th>\n",
       "      <th>Local_feature_6</th>\n",
       "      <th>Local_feature_7</th>\n",
       "      <th>Local_feature_8</th>\n",
       "      <th>Local_feature_9</th>\n",
       "      <th>Local_feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>in_BTC_min</th>\n",
       "      <th>in_BTC_max</th>\n",
       "      <th>in_BTC_mean</th>\n",
       "      <th>in_BTC_median</th>\n",
       "      <th>in_BTC_total</th>\n",
       "      <th>out_BTC_min</th>\n",
       "      <th>out_BTC_max</th>\n",
       "      <th>out_BTC_mean</th>\n",
       "      <th>out_BTC_median</th>\n",
       "      <th>out_BTC_total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>txId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.169615</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160199</td>\n",
       "      <td>-0.166062</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>8.301504e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>8.904096e-05</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.127429</td>\n",
       "      <td>-0.133751</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>2.915711e-04</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>9.357923e-04</td>\n",
       "      <td>0.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.170103</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.160699</td>\n",
       "      <td>-0.166555</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.134016e-04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7.612341e-05</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.114267</td>\n",
       "      <td>-0.184668</td>\n",
       "      <td>-1.201369</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>0.547008</td>\n",
       "      <td>-0.161652</td>\n",
       "      <td>-0.118555</td>\n",
       "      <td>0.300047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>6.113009e-04</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001552</td>\n",
       "      <td>1.552291e-03</td>\n",
       "      <td>0.000817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>5.202107</td>\n",
       "      <td>-0.210553</td>\n",
       "      <td>-1.756361</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>260.090707</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>5.335864</td>\n",
       "      <td>5.252974</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>0.074805</td>\n",
       "      <td>6.466160e-11</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.451405e-07</td>\n",
       "      <td>0.074805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.558398</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.584665</td>\n",
       "      <td>0.568363</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>8.223464e-04</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>1.933576e-02</td>\n",
       "      <td>0.010179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.547658</td>\n",
       "      <td>-0.198956</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.573676</td>\n",
       "      <td>0.557528</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>1.012352e-05</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>1.905181e-02</td>\n",
       "      <td>0.010029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.543600</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.569524</td>\n",
       "      <td>0.553434</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>4.604647e-04</td>\n",
       "      <td>0.009961</td>\n",
       "      <td>0.018945</td>\n",
       "      <td>1.894453e-02</td>\n",
       "      <td>0.009973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0.537760</td>\n",
       "      <td>-0.198853</td>\n",
       "      <td>-0.091383</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>0.547543</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>1.505606e-04</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>1.879015e-02</td>\n",
       "      <td>0.009891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>-0.170463</td>\n",
       "      <td>-0.152788</td>\n",
       "      <td>1.018602</td>\n",
       "      <td>-0.121970</td>\n",
       "      <td>-0.063725</td>\n",
       "      <td>-0.113002</td>\n",
       "      <td>-0.061584</td>\n",
       "      <td>-0.161066</td>\n",
       "      <td>-0.166917</td>\n",
       "      <td>-0.049707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>1.987330e-04</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1.332511e-04</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202804 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Local_feature_1  Local_feature_2  Local_feature_3  Local_feature_4  \\\n",
       "txId                                                                       \n",
       "NaN         -0.169615        -0.184668        -1.201369        -0.121970   \n",
       "NaN         -0.137586        -0.184668        -1.201369        -0.121970   \n",
       "NaN         -0.170103        -0.184668        -1.201369        -0.121970   \n",
       "NaN         -0.114267        -0.184668        -1.201369         0.028105   \n",
       "NaN          5.202107        -0.210553        -1.756361        -0.121970   \n",
       "...               ...              ...              ...              ...   \n",
       "NaN          0.558398        -0.198956        -0.091383        -0.121970   \n",
       "NaN          0.547658        -0.198956        -0.091383        -0.121970   \n",
       "NaN          0.543600        -0.198853        -0.091383        -0.121970   \n",
       "NaN          0.537760        -0.198853        -0.091383        -0.121970   \n",
       "NaN         -0.170463        -0.152788         1.018602        -0.121970   \n",
       "\n",
       "      Local_feature_5  Local_feature_6  Local_feature_7  Local_feature_8  \\\n",
       "txId                                                                       \n",
       "NaN         -0.043875        -0.113002        -0.061584        -0.160199   \n",
       "NaN         -0.043875        -0.113002        -0.061584        -0.127429   \n",
       "NaN         -0.043875        -0.113002        -0.061584        -0.160699   \n",
       "NaN         -0.043875        -0.113002         0.547008        -0.161652   \n",
       "NaN        260.090707        -0.113002        -0.061584         5.335864   \n",
       "...               ...              ...              ...              ...   \n",
       "NaN         -0.043875        -0.113002        -0.061584         0.584665   \n",
       "NaN         -0.043875        -0.113002        -0.061584         0.573676   \n",
       "NaN         -0.043875        -0.113002        -0.061584         0.569524   \n",
       "NaN         -0.043875        -0.113002        -0.061584         0.563549   \n",
       "NaN         -0.063725        -0.113002        -0.061584        -0.161066   \n",
       "\n",
       "      Local_feature_9  Local_feature_10  ...  in_BTC_min  in_BTC_max  \\\n",
       "txId                                     ...                           \n",
       "NaN         -0.166062         -0.049707  ...    0.000047    0.000047   \n",
       "NaN         -0.133751         -0.049707  ...    0.000493    0.000493   \n",
       "NaN         -0.166555         -0.049707  ...    0.000040    0.000040   \n",
       "NaN         -0.118555          0.300047  ...    0.000027    0.000702   \n",
       "NaN          5.252974         -0.049707  ...    0.074805    0.074805   \n",
       "...               ...               ...  ...         ...         ...   \n",
       "NaN          0.568363         -0.049707  ...    0.010179    0.010179   \n",
       "NaN          0.557528         -0.049707  ...    0.010029    0.010029   \n",
       "NaN          0.553434         -0.049707  ...    0.009973    0.009973   \n",
       "NaN          0.547543         -0.049707  ...    0.009891    0.009891   \n",
       "NaN         -0.166917         -0.049707  ...    0.000035    0.000035   \n",
       "\n",
       "      in_BTC_mean  in_BTC_median  in_BTC_total   out_BTC_min  out_BTC_max  \\\n",
       "txId                                                                        \n",
       "NaN      0.000047       0.000047      0.000047  8.301504e-05     0.000032   \n",
       "NaN      0.000493       0.000493      0.000493  2.915711e-04     0.000444   \n",
       "NaN      0.000040       0.000040      0.000040  1.134016e-04     0.000020   \n",
       "NaN      0.000272       0.000088      0.000817  6.113009e-04     0.000714   \n",
       "NaN      0.074805       0.074805      0.074805  6.466160e-11     0.003648   \n",
       "...           ...            ...           ...           ...          ...   \n",
       "NaN      0.010179       0.010179      0.010179  8.223464e-04     0.010104   \n",
       "NaN      0.010029       0.010029      0.010029  1.012352e-05     0.010098   \n",
       "NaN      0.009973       0.009973      0.009973  4.604647e-04     0.009961   \n",
       "NaN      0.009891       0.009891      0.009891  1.505606e-04     0.009935   \n",
       "NaN      0.000035       0.000035      0.000035  1.987330e-04     0.000035   \n",
       "\n",
       "      out_BTC_mean  out_BTC_median  out_BTC_total  \n",
       "txId                                               \n",
       "NaN       0.000089    8.904096e-05       0.000047  \n",
       "NaN       0.000936    9.357923e-04       0.000493  \n",
       "NaN       0.000076    7.612341e-05       0.000040  \n",
       "NaN       0.001552    1.552291e-03       0.000817  \n",
       "NaN       0.000022    1.451405e-07       0.074805  \n",
       "...            ...             ...            ...  \n",
       "NaN       0.019336    1.933576e-02       0.010179  \n",
       "NaN       0.019052    1.905181e-02       0.010029  \n",
       "NaN       0.018945    1.894453e-02       0.009973  \n",
       "NaN       0.018790    1.879015e-02       0.009891  \n",
       "NaN       0.000133    1.332511e-04       0.000035  \n",
       "\n",
       "[202804 rows x 182 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "ids_from_features = df_txs_features.index.to_series()\n",
    "ids_from_src      = df_txs_edgelist['txId1']\n",
    "ids_from_dst      = df_txs_edgelist['txId2']\n",
    "\n",
    "# 203769\n",
    "all_ids = pd.unique(pd.concat([ids_from_src, ids_from_dst]))\n",
    "id_map  = {orig_id: idx for idx, orig_id in enumerate(all_ids)}\n",
    "\n",
    "src = df_txs_edgelist['txId1'].map(id_map).values\n",
    "dst = df_txs_edgelist['txId2'].map(id_map).values\n",
    "edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "len(all_ids)\n",
    "df_txs_features.index = df_txs_features.index.map(id_map)\n",
    "df_txs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[202804, 182], edge_index=[2, 22], y=txId\n",
       "3321         2\n",
       "11108        2\n",
       "51816        2\n",
       "68869        0\n",
       "89273        0\n",
       "            ..\n",
       "194747812    2\n",
       "194747925    2\n",
       "194748063    2\n",
       "194748070    2\n",
       "194835939    2\n",
       "Name: class, Length: 202804, dtype: int64, train_mask=txId\n",
       "3321          True\n",
       "11108         True\n",
       "51816         True\n",
       "68869         True\n",
       "89273         True\n",
       "             ...  \n",
       "194747812    False\n",
       "194747925    False\n",
       "194748063    False\n",
       "194748070    False\n",
       "194835939    False\n",
       "Name: Time step, Length: 202804, dtype: bool, test_mask=txId\n",
       "3321         False\n",
       "11108        False\n",
       "51816        False\n",
       "68869        False\n",
       "89273        False\n",
       "             ...  \n",
       "194747812     True\n",
       "194747925     True\n",
       "194748063     True\n",
       "194748070     True\n",
       "194835939     True\n",
       "Name: Time step, Length: 202804, dtype: bool)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(df_txs_features.values, dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index, y=y, train_mask=train_mask, test_mask=test_mask)\n",
    "data\n",
    "data.y = torch.from_numpy(data.y.to_numpy().astype(int)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_mask', 'pos_edge_label', 'test_mask', 'y', 'pos_edge_label_index', 'edge_index', 'neg_edge_label_index', 'neg_edge_label', 'x']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "\n",
    "splitter = RandomLinkSplit(\n",
    "    is_undirected=False,\n",
    "    split_labels=True,          \n",
    "    add_negative_train_samples=True,\n",
    "    neg_sampling_ratio=1.0,\n",
    "    num_val=0,\n",
    "    num_test=0,\n",
    ")\n",
    "train_data, val_data, test_data = splitter(data)\n",
    "print(train_data.keys())\n",
    "train_data.pos_edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Loss=1.5783 (AE=0.7920, CLF=0.7863\n",
      "Epoch 002 | Loss=1.0372 (AE=0.7822, CLF=0.2551\n",
      "Epoch 003 | Loss=1.0746 (AE=0.7932, CLF=0.2814\n",
      "Epoch 004 | Loss=1.0500 (AE=0.7791, CLF=0.2709\n",
      "Epoch 005 | Loss=1.0047 (AE=0.7617, CLF=0.2430\n",
      "Epoch 006 | Loss=0.9597 (AE=0.7425, CLF=0.2172\n",
      "Epoch 007 | Loss=0.9359 (AE=0.7311, CLF=0.2048\n",
      "Epoch 008 | Loss=0.9278 (AE=0.7254, CLF=0.2024\n",
      "Epoch 009 | Loss=0.9122 (AE=0.7121, CLF=0.2001\n",
      "Epoch 010 | Loss=0.8880 (AE=0.6991, CLF=0.1888\n",
      "Test Acc=0.9088 | Precision=0.6810 | Recall=0.7891 | F1=0.7181\n",
      "Epoch 011 | Loss=0.8601 (AE=0.6864, CLF=0.1737\n",
      "Epoch 012 | Loss=0.8522 (AE=0.6864, CLF=0.1657\n",
      "Epoch 013 | Loss=0.8523 (AE=0.6864, CLF=0.1659\n",
      "Epoch 014 | Loss=0.8513 (AE=0.6864, CLF=0.1649\n",
      "Epoch 015 | Loss=0.8429 (AE=0.6864, CLF=0.1565\n",
      "Epoch 016 | Loss=0.8310 (AE=0.6864, CLF=0.1446\n",
      "Epoch 017 | Loss=0.8234 (AE=0.6864, CLF=0.1370\n",
      "Epoch 018 | Loss=0.8220 (AE=0.6864, CLF=0.1356\n",
      "Epoch 019 | Loss=0.8202 (AE=0.6864, CLF=0.1337\n",
      "Epoch 020 | Loss=0.8134 (AE=0.6864, CLF=0.1269\n",
      "Test Acc=0.9279 | Precision=0.7222 | Recall=0.8061 | F1=0.7555\n",
      "Epoch 021 | Loss=0.8062 (AE=0.6864, CLF=0.1198\n",
      "Epoch 022 | Loss=0.8038 (AE=0.6864, CLF=0.1174\n",
      "Epoch 023 | Loss=0.8040 (AE=0.6864, CLF=0.1176\n",
      "Epoch 024 | Loss=0.8016 (AE=0.6864, CLF=0.1152\n",
      "Epoch 025 | Loss=0.7965 (AE=0.6864, CLF=0.1101\n",
      "Epoch 026 | Loss=0.7929 (AE=0.6864, CLF=0.1065\n",
      "Epoch 027 | Loss=0.7918 (AE=0.6864, CLF=0.1054\n",
      "Epoch 028 | Loss=0.7898 (AE=0.6864, CLF=0.1034\n",
      "Epoch 029 | Loss=0.7860 (AE=0.6864, CLF=0.0996\n",
      "Epoch 030 | Loss=0.7831 (AE=0.6864, CLF=0.0967\n",
      "Test Acc=0.9355 | Precision=0.7414 | Recall=0.7844 | F1=0.7607\n",
      "Epoch 031 | Loss=0.7822 (AE=0.6864, CLF=0.0958\n",
      "Epoch 032 | Loss=0.7809 (AE=0.6864, CLF=0.0945\n",
      "Epoch 033 | Loss=0.7781 (AE=0.6864, CLF=0.0917\n",
      "Epoch 034 | Loss=0.7757 (AE=0.6864, CLF=0.0892\n",
      "Epoch 035 | Loss=0.7748 (AE=0.6864, CLF=0.0884\n",
      "Epoch 036 | Loss=0.7733 (AE=0.6864, CLF=0.0869\n",
      "Epoch 037 | Loss=0.7709 (AE=0.6864, CLF=0.0844\n",
      "Epoch 038 | Loss=0.7695 (AE=0.6864, CLF=0.0831\n",
      "Epoch 039 | Loss=0.7685 (AE=0.6864, CLF=0.0820\n",
      "Epoch 040 | Loss=0.7665 (AE=0.6864, CLF=0.0801\n",
      "Test Acc=0.9400 | Precision=0.7571 | Recall=0.7938 | F1=0.7739\n",
      "Epoch 041 | Loss=0.7648 (AE=0.6864, CLF=0.0784\n",
      "Epoch 042 | Loss=0.7639 (AE=0.6864, CLF=0.0775\n",
      "Epoch 043 | Loss=0.7624 (AE=0.6864, CLF=0.0760\n",
      "Epoch 044 | Loss=0.7606 (AE=0.6864, CLF=0.0741\n",
      "Epoch 045 | Loss=0.7596 (AE=0.6864, CLF=0.0732\n",
      "Epoch 046 | Loss=0.7586 (AE=0.6864, CLF=0.0722\n",
      "Epoch 047 | Loss=0.7571 (AE=0.6864, CLF=0.0707\n",
      "Epoch 048 | Loss=0.7559 (AE=0.6864, CLF=0.0695\n",
      "Epoch 049 | Loss=0.7550 (AE=0.6864, CLF=0.0686\n",
      "Epoch 050 | Loss=0.7537 (AE=0.6864, CLF=0.0673\n",
      "Test Acc=0.9434 | Precision=0.7711 | Recall=0.7737 | F1=0.7724\n",
      "Epoch 051 | Loss=0.7527 (AE=0.6864, CLF=0.0663\n",
      "Epoch 052 | Loss=0.7518 (AE=0.6864, CLF=0.0654\n",
      "Epoch 053 | Loss=0.7506 (AE=0.6864, CLF=0.0642\n",
      "Epoch 054 | Loss=0.7497 (AE=0.6864, CLF=0.0632\n",
      "Epoch 055 | Loss=0.7489 (AE=0.6864, CLF=0.0625\n",
      "Epoch 056 | Loss=0.7477 (AE=0.6864, CLF=0.0613\n",
      "Epoch 057 | Loss=0.7468 (AE=0.6864, CLF=0.0604\n",
      "Epoch 058 | Loss=0.7460 (AE=0.6864, CLF=0.0596\n",
      "Epoch 059 | Loss=0.7450 (AE=0.6864, CLF=0.0585\n",
      "Epoch 060 | Loss=0.7442 (AE=0.6864, CLF=0.0578\n",
      "Test Acc=0.9431 | Precision=0.7695 | Recall=0.7774 | F1=0.7734\n",
      "Epoch 061 | Loss=0.7433 (AE=0.6864, CLF=0.0569\n",
      "Epoch 062 | Loss=0.7424 (AE=0.6864, CLF=0.0560\n",
      "Epoch 063 | Loss=0.7417 (AE=0.6864, CLF=0.0552\n",
      "Epoch 064 | Loss=0.7408 (AE=0.6864, CLF=0.0544\n",
      "Epoch 065 | Loss=0.7401 (AE=0.6864, CLF=0.0537\n",
      "Epoch 066 | Loss=0.7393 (AE=0.6864, CLF=0.0528\n",
      "Epoch 067 | Loss=0.7385 (AE=0.6864, CLF=0.0521\n",
      "Epoch 068 | Loss=0.7378 (AE=0.6864, CLF=0.0514\n",
      "Epoch 069 | Loss=0.7370 (AE=0.6864, CLF=0.0506\n",
      "Epoch 070 | Loss=0.7363 (AE=0.6864, CLF=0.0499\n",
      "Test Acc=0.9476 | Precision=0.7918 | Recall=0.7673 | F1=0.7789\n",
      "Epoch 071 | Loss=0.7356 (AE=0.6864, CLF=0.0492\n",
      "Epoch 072 | Loss=0.7349 (AE=0.6864, CLF=0.0485\n",
      "Epoch 073 | Loss=0.7342 (AE=0.6864, CLF=0.0478\n",
      "Epoch 074 | Loss=0.7335 (AE=0.6864, CLF=0.0471\n",
      "Epoch 075 | Loss=0.7328 (AE=0.6864, CLF=0.0464\n",
      "Epoch 076 | Loss=0.7322 (AE=0.6864, CLF=0.0457\n",
      "Epoch 077 | Loss=0.7315 (AE=0.6864, CLF=0.0451\n",
      "Epoch 078 | Loss=0.7308 (AE=0.6864, CLF=0.0444\n",
      "Epoch 079 | Loss=0.7301 (AE=0.6864, CLF=0.0437\n",
      "Epoch 080 | Loss=0.7295 (AE=0.6864, CLF=0.0431\n",
      "Test Acc=0.9552 | Precision=0.8406 | Recall=0.7633 | F1=0.7961\n",
      "Epoch 081 | Loss=0.7288 (AE=0.6864, CLF=0.0424\n",
      "Epoch 082 | Loss=0.7282 (AE=0.6864, CLF=0.0418\n",
      "Epoch 083 | Loss=0.7276 (AE=0.6864, CLF=0.0412\n",
      "Epoch 084 | Loss=0.7270 (AE=0.6864, CLF=0.0406\n",
      "Epoch 085 | Loss=0.7264 (AE=0.6864, CLF=0.0399\n",
      "Epoch 086 | Loss=0.7258 (AE=0.6864, CLF=0.0393\n",
      "Epoch 087 | Loss=0.7252 (AE=0.6864, CLF=0.0388\n",
      "Epoch 088 | Loss=0.7246 (AE=0.6864, CLF=0.0382\n",
      "Epoch 089 | Loss=0.7240 (AE=0.6864, CLF=0.0376\n",
      "Epoch 090 | Loss=0.7235 (AE=0.6864, CLF=0.0370\n",
      "Test Acc=0.9575 | Precision=0.8681 | Recall=0.7499 | F1=0.7958\n",
      "Epoch 091 | Loss=0.7229 (AE=0.6864, CLF=0.0365\n",
      "Epoch 092 | Loss=0.7223 (AE=0.6864, CLF=0.0359\n",
      "Epoch 093 | Loss=0.7218 (AE=0.6864, CLF=0.0354\n",
      "Epoch 094 | Loss=0.7212 (AE=0.6864, CLF=0.0348\n",
      "Epoch 095 | Loss=0.7207 (AE=0.6864, CLF=0.0343\n",
      "Epoch 096 | Loss=0.7201 (AE=0.6864, CLF=0.0337\n",
      "Epoch 097 | Loss=0.7196 (AE=0.6864, CLF=0.0332\n",
      "Epoch 098 | Loss=0.7191 (AE=0.6864, CLF=0.0327\n",
      "Epoch 099 | Loss=0.7186 (AE=0.6864, CLF=0.0322\n",
      "Epoch 100 | Loss=0.7181 (AE=0.6864, CLF=0.0316\n",
      "Test Acc=0.9572 | Precision=0.8814 | Recall=0.7326 | F1=0.7861\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GAE\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# 2) Encoder + Classifier\n",
    "class GAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "class NodeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, num_classes)\n",
    "    def forward(self, z):\n",
    "        return self.lin(z)\n",
    "\n",
    "in_feats    = data.num_node_features\n",
    "hidden_dim  = 128\n",
    "out_dim     = 64\n",
    "num_classes = int(data.y[data.y != 2].max() + 1)\n",
    "\n",
    "encoder    = GAEEncoder(in_feats, hidden_dim, out_dim)\n",
    "gae_model  = GAE(encoder)\n",
    "classifier = NodeClassifier(out_dim, num_classes)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(gae_model.parameters()) + list(classifier.parameters()),\n",
    "    lr=0.01\n",
    ")\n",
    "bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "ce_loss  = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# 3) train() 改用 train_pos/neg\n",
    "def train():\n",
    "    gae_model.train()\n",
    "    classifier.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # encode on train positive edges\n",
    "    z = gae_model.encode(train_data.x, train_data.pos_edge_label_index)\n",
    "\n",
    "    # AE loss (pos + neg)\n",
    "    pos = train_data.pos_edge_label_index\n",
    "    neg = train_data.neg_edge_label_index\n",
    "    edge_all = torch.cat([pos, neg], dim=1)\n",
    "    logits_ae = gae_model.decode(z, edge_all)\n",
    "    labels_ae = torch.cat([\n",
    "        torch.ones(pos.size(1), device=logits_ae.device),\n",
    "        torch.zeros(neg.size(1), device=logits_ae.device),\n",
    "    ])\n",
    "    loss_ae = bce_loss(logits_ae, labels_ae)\n",
    "\n",
    "    # classification loss (only known & train_mask)\n",
    "    # print(len(train_data.y != 2))\n",
    "    train_mask = torch.tensor(train_data.train_mask.values, dtype=torch.bool)\n",
    "   \n",
    "    for i in range(len(train_mask)):\n",
    "        train_mask[i] = train_mask[i] and (train_data.y[i] != 2)\n",
    "    mask = train_mask\n",
    "    #print(mask[mask == True].shape)\n",
    "    #print(mask.shape)\n",
    "    logits_cls = classifier(z)\n",
    "    loss_cls = ce_loss(logits_cls[mask], train_data.y[mask])\n",
    "    #print(loss_ae)\n",
    "    loss = loss_ae + loss_cls\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), loss_ae.item(), loss_cls.item()\n",
    "\n",
    "# 4) evaluate() 只用 train_data.train_pos_edge_index encode\n",
    "def evaluate():\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        z = gae_model.encode(data.x, data.edge_index) \n",
    "        logits = classifier(z)\n",
    "        preds  = logits.argmax(dim=1)\n",
    "   \n",
    "        test_mask = torch.tensor(data.test_mask.values, dtype=torch.bool) & (data.y != 2)\n",
    "  \n",
    "        mask = test_mask\n",
    "        y_true = data.y[mask].cpu().numpy()\n",
    "        y_pred = preds[mask].cpu().numpy()\n",
    "\n",
    "        acc  = (y_true == y_pred).mean().item()\n",
    "        prec = precision_score(y_true, y_pred, average='macro')\n",
    "        rec  = recall_score(y_true, y_pred, average='macro')\n",
    "        f1   = f1_score(y_true, y_pred, average='macro')\n",
    "        print(f\"Test Acc={acc:.4f} | \"\n",
    "              f\"Precision={prec:.4f} | \"\n",
    "              f\"Recall={rec:.4f} | \"\n",
    "              f\"F1={f1:.4f}\")\n",
    "        return acc\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss_tot, loss_ae, loss_cls = train()\n",
    "    print(f\"Epoch {epoch:03d} | \"\n",
    "              f\"Loss={loss_tot:.4f} (AE={loss_ae:.4f}, CLF={loss_cls:.4f})\")\n",
    "    if epoch % 10 == 0:\n",
    "        test_acc= evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DRL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
